{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import arcpy module\n",
    "import arcpy, time, os, sys\n",
    "import pandas as pd\n",
    "from logging.handlers import RotatingFileHandler\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Set\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "arcpy.SetProgressor(\"default\",\"Initiating HAZUS Analysis...\")\n",
    "\n",
    "HAZUS_FP = r'C:\\Users\\USMC714671\\OneDrive - WSP O365\\OneDrive - Development Folders\\Dev_Apps\\HMP_Tools\\HMP_Tools\\temp_tool_data.gdb\\Bryan_UDF_Results'\n",
    "FHA = r'C:\\Users\\USMC714671\\OneDrive - WSP O365\\OneDrive - Development Folders\\Dev_Apps\\HMP_Tools\\HMP_Tools\\temp_tool_data.gdb\\BRAZOS_FEMA_NFHL_S_FLD_HAZ_AR'\n",
    "Dis_Fld = 'Ranking'\n",
    "Output_GDB = r'C:\\Users\\USMC714671\\OneDrive - WSP O365\\OneDrive - Development Folders\\Dev_Apps\\HMP_Tools\\HMP_Tools\\Work.gdb'\n",
    "output_folder = r'C:\\Users\\USMC714671\\OneDrive - WSP O365\\OneDrive - Development Folders\\Dev_Apps\\HMP_Tools\\HMP_Tools\\Temp_Folder'\n",
    "\n",
    "FLD_List = {}\n",
    "Sub_List = {}\n",
    "\n",
    "# Script Argument\n",
    "default_gdb = r'C:\\Users\\USMC714671\\OneDrive - WSP O365\\OneDrive - Development Folders\\Dev_Apps\\HMP_Tools\\HMP_Tools\\scratch.gdb'\n",
    "\n",
    "# get the location of the csv template file in FFRMS_Bin\n",
    "def xlsxPath(x):\n",
    "    cDir = os.getcwd()\n",
    "    xsNm = x\n",
    "    exPath = os.path.join(cDir,xsNm)\n",
    "    return exPath\n",
    "\n",
    "# get the file name from a given file path\n",
    "def get_file_name(file_path):\n",
    "    return Path(file_path).name\n",
    "\n",
    "# get a list of keys from the dictionary that match the list of target values - \n",
    "# the list will build in the order of the dictionary and list\n",
    "def get_keys_by_value(dictionary, target_value):\n",
    "    key_list = []\n",
    "    for key, value in dictionary.items():\n",
    "        if value == target_value:\n",
    "            key_list.append(key)\n",
    "    return key_list\n",
    "\n",
    "arcpy.SetProgressor(\"default\",\"Joining HAZUS Results and FHA data...\")\n",
    "join_fm = arcpy.FieldMappings() # create a field map object\n",
    "join_fm.addTable(HAZUS_FP) # add the HAZUS atrributes fields to the object\n",
    "join_fm.addTable(FHA) # add the FHA attributes to the object\n",
    "\n",
    "\n",
    "join_fc = default_gdb+\"\\\\HAZUS_FHA_Join\"\n",
    "arcpy.analysis.SpatialJoin(HAZUS_FP,FHA,join_fc,\"JOIN_ONE_TO_ONE\",\"KEEP_ALL\",join_fm,\"INTERSECT\")\n",
    "\n",
    "calc_tbl = default_gdb+\"\\\\HAZUS_FHA_Join\"\n",
    "\n",
    "arcpy.SetProgressor(\"default\",\"Adding Hazus Summary Fields...\")\n",
    "\n",
    "# Add building count field and auto fill value of 1 for each row\n",
    "def buildingcount(x):\n",
    "    arcpy.SetProgressor(\"default\",\"Adding Building Count Values...\")\n",
    "    arcpy.management.AddField(calc_tbl,\"Bldg_Count\",\"DOUBLE\")\n",
    "    bldg_count = arcpy.management.CalculateField(calc_tbl,\"Bldg_Count\",x,\"PYTHON3\",\"\",\"\", \"ENFORCE_DOMAINS\")\n",
    "    arcpy.SetProgressorPosition()\n",
    "    return bldg_count\n",
    "buildingcount(1)\n",
    "\n",
    "# Add Total Building Cost field and calculate from existing fields\n",
    "arcpy.SetProgressor(\"default\",\"Adding Building Total Values...\")\n",
    "arcpy.management.AddField(calc_tbl,\"TotalBldgValue\",\"DOUBLE\")\n",
    "\n",
    "time.sleep(2) # delay script for 2 seconds\n",
    "\n",
    "arcpy.management.CalculateField(calc_tbl,\"TotalBldgValue\",\"!BldgCost! + !ContentCos!\",\"PYTHON3\",\"\",\"\", \"ENFORCE_DOMAINS\")\n",
    "arcpy.SetProgressorPosition()\n",
    "\n",
    "time.sleep(2) # delay script for 2 seconds\n",
    "\n",
    "# Add Total Damage field and calculate from existing fields\n",
    "arcpy.SetProgressor(\"default\",\"Adding Estimated Total Damage Values...\")\n",
    "arcpy.management.AddField(calc_tbl,\"EstTot_Damage\",\"DOUBLE\")\n",
    "\n",
    "time.sleep(2) # delay script for 2 seconds\n",
    "\n",
    "arcpy.management.CalculateField(calc_tbl,\"EstTot_Damage\",\"!BldgLossUS! + !ContentLos!\",\"PYTHON3\",\"\",\"\", \"ENFORCE_DOMAINS\")\n",
    "arcpy.SetProgressorPosition()\n",
    "\n",
    "# Run Summary Statistics for output table\n",
    "arcpy.SetProgressor(\"default\",\"Calculating HAZUS Results Table Data...\")\n",
    "dissolve_fields = [\"Type_oc\",Dis_Fld]\n",
    "arcpy.management.Dissolve(calc_tbl,default_gdb+\"\\\\HAZUS_FHA_Dissolve\",dissolve_fields,[[\"Bldg_Count\",\"SUM\"],[\"EstTot_Damage\",\"SUM\"],[\"ContentLos\",\"SUM\"],[\"TotalBldgValue\",\"SUM\"],[\"BldgLossUS\",\"SUM\"]])\n",
    "\n",
    "time.sleep(2) # delay script for 2 seconds\n",
    "\n",
    "calc_tbl1 = default_gdb+\"\\\\HAZUS_FHA_Dissolve\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ranking          Flood Zone                             Subtype\n",
      "0         0  NP - NOT POPULATED                                 NaN\n",
      "1         1   AREA NOT INCLUDED                                 NaN\n",
      "2         2                   D                                 NaN\n",
      "3         3                   X                                 NaN\n",
      "4         4          Open Water                                 NaN\n",
      "5         5                   X  0.2 PCT ANNUAL CHANCE FLOOD HAZARD\n",
      "6         6                   V                                 NaN\n",
      "7         7                  VE                                 NaN\n",
      "8         8                 A99                                 NaN\n",
      "9         9   AREA NOT INCLUDED                                 NaN\n",
      "10       10                  AO                                 NaN\n",
      "11       11                  AH                                 NaN\n",
      "12       12                   A                                 NaN\n",
      "13       13                  AE                                 NaN\n",
      "14       14                  AE                            FLOODWAY\n",
      "{0: 'NP - NOT POPULATED', 1: 'AREA NOT INCLUDED', 2: 'D', 3: 'X', 4: 'Open Water', 5: 'X', 6: 'V', 7: 'VE', 8: 'A99', 9: 'AREA NOT INCLUDED', 10: 'AO', 11: 'AH', 12: 'A', 13: 'AE', 14: 'AE'}\n",
      "{0: nan, 1: nan, 2: nan, 3: nan, 4: nan, 5: '0.2 PCT ANNUAL CHANCE FLOOD HAZARD', 6: nan, 7: nan, 8: nan, 9: nan, 10: nan, 11: nan, 12: nan, 13: nan, 14: 'FLOODWAY'}\n",
      "AE\n",
      "nan\n",
      "AE\n",
      "FLOODWAY\n",
      "AE\n",
      "nan\n",
      "AE\n",
      "FLOODWAY\n",
      "AE\n",
      "nan\n",
      "AE\n",
      "FLOODWAY\n",
      "A\n",
      "nan\n",
      "AE\n",
      "nan\n",
      "AE\n",
      "FLOODWAY\n"
     ]
    }
   ],
   "source": [
    "# Import arcpy module\n",
    "import arcpy, time, os, sys\n",
    "import pandas as pd\n",
    "from logging.handlers import RotatingFileHandler\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Set\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# creat DataFrame from draft eff csv\n",
    "df = pd.read_csv(xlsxPath('SFHA_Rankings.csv'),na_values='')\n",
    "print(df)\n",
    "\n",
    "for value, index in enumerate(df['Flood Zone']):\n",
    "    FLD_List[value] = index\n",
    "\n",
    "for value, index in enumerate(df['Subtype']):\n",
    "    Sub_List[value] = index\n",
    "\n",
    "\n",
    "print(FLD_List)\n",
    "print(Sub_List)\n",
    "\n",
    "calc_tbl1 = default_gdb+\"\\\\HAZUS_FHA_Dissolve\"\n",
    "\n",
    "# Add Loss Ratio field and calculate from existing fields\n",
    "arcpy.SetProgressor(\"default\",\"Adding Loss Ratio Values...\")\n",
    "arcpy.management.AddField(calc_tbl1,\"LossRatio\",\"DOUBLE\")\n",
    "arcpy.management.AddField(calc_tbl1,\"FLD_ZONE\",\"TEXT\")\n",
    "arcpy.management.AddField(calc_tbl1,\"Subtype\",\"TEXT\")\n",
    "\n",
    "\n",
    "edit = arcpy.da.Editor(default_gdb)\n",
    "edit.startEditing(False, True)\n",
    "\n",
    "with arcpy.da.UpdateCursor(calc_tbl1, ['FLD_ZONE', 'Subtype','Ranking']) as cursor:\n",
    "    for row in cursor:\n",
    "        # Check the condition\n",
    "        fldzone = FLD_List.get(row[2], 'default_value_for_FLD_ZONE')\n",
    "        print(fldzone)\n",
    "        subtype = Sub_List.get(row[2], 'default_value_for_Subtype')\n",
    "        print(subtype)\n",
    "        row[0] = fldzone\n",
    "        cursor.updateRow(row)\n",
    "        row[1] = subtype\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "edit.stopEditing(True)\n",
    "\n",
    "\n",
    "arcpy.management.CalculateField(calc_tbl1,\"LossRatio\",\"!SUM_EstTot_Damage! / !SUM_TotalBldgValue!\",\"PYTHON3\",\"\",\"\", \"ENFORCE_DOMAINS\")\n",
    "arcpy.SetProgressorPosition()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Lines 61-79 reorder the fields of the output table to meet the format of the HAZUS table\n",
    "# Get a list of field names in the current order\n",
    "fields = arcpy.ListFields(calc_tbl1)\n",
    "field_names = [fld.name for fld in arcpy.ListFields(calc_tbl1)]\n",
    "\n",
    "# Specify the desired field order\n",
    "out_fld_order = [\"OBJECTID\",\"Type_Oc\",'FLD_ZONE','Subtype',\"SUM_Bldg_Count\",\"SUM_TotalBldgValue\",\"SUM_BldgLossUS\",\"SUM_ContentLos\",\"SUM_EstTot_Damage\",\"LossRatio\"]\n",
    "\n",
    "# Create a new field mapping object\n",
    "fm = arcpy.FieldMappings()\n",
    "\n",
    "# Add fields to the field mapping in the desired order\n",
    "for fld_nm in out_fld_order:\n",
    "    # assign index to field based on output list order\n",
    "    field_index2 = field_names.index(fld_nm)\n",
    "    # create field map object\n",
    "    field_map = arcpy.FieldMap()\n",
    "    # add the input fields from the input feature class\n",
    "    field_map.addInputField(calc_tbl1,fld_nm)\n",
    "    # add the new field map for each field to the field mappings parameter\n",
    "    fm.addFieldMap(field_map)\n",
    "\n",
    "# Copy the table to a new table with reordered fields\n",
    "output_table = \"HAZUS_100yr_UDF_Results_By_Flood_Zone.csv\"\n",
    "arcpy.conversion.TableToTable(calc_tbl1, output_folder, output_table,\"\",fm)\n",
    "arcpy.SetProgressorPosition()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
